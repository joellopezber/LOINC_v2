import logging
from typing import Dict, Any, List, Optional
from ...lazy_load_service import LazyLoadService, lazy_load
from ...service_locator import service_locator

logger = logging.getLogger(__name__)

class OntologyService(LazyLoadService):
    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(OntologyService, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        """Inicializa el servicio de ontolog√≠a"""
        if hasattr(self, '_initialized'):
            return
            
        super().__init__()
        logger.debug("üîç Inicializando Ontology service")
        
        try:
            self._openai = None
            self._storage = None
            self._set_initialized(True)
        except Exception as e:
            self._set_initialized(False, str(e))
            raise

    @property
    def openai_service(self):
        """Obtiene el OpenAIService"""
        if not self._openai_service:
            self._openai_service = service_locator.get('openai')
            if not self._openai_service:
                logger.error("‚ùå No se pudo obtener OpenAIService del service_locator")
                return None
            logger.info("‚úÖ OpenAIService obtenido del service_locator")
        return self._openai_service

    def _clean_json_response(self, response: str) -> str:
        """
        Limpia la respuesta de OpenAI para obtener un JSON v√°lido
        1. Elimina los bloques de c√≥digo markdown
        2. Elimina los comentarios del JSON
        3. Encuentra el JSON v√°lido
        """
        # 1. Eliminar bloques de c√≥digo markdown
        response = re.sub(r'```json\n|\n```', '', response)
        
        # 2. Eliminar comentarios del JSON
        response = re.sub(r'//.*$', '', response, flags=re.MULTILINE)
        
        # 3. Encontrar el primer JSON v√°lido
        json_match = re.search(r'(\{.*\})', response, re.DOTALL)
        if not json_match:
            raise ValueError("No se encontr√≥ un JSON v√°lido en la respuesta")
            
        json_str = json_match.group(1)
        
        # 4. Limpiar espacios extra y l√≠neas vac√≠as
        json_str = re.sub(r',(\s*[\]}])', r'\1', json_str)
        
        return json_str

    def _validate_response(self, response: str) -> bool:
        """
        Valida que la respuesta tenga el formato JSON esperado
        Args:
            response: Respuesta de OpenAI
        Returns:
            bool: True si la respuesta es v√°lida
        """
        try:
            # Log de la respuesta completa para debug
            logger.debug("üìù Respuesta completa recibida:")
            logger.debug("-" * 40)
            logger.debug(response)
            logger.debug("-" * 40)

            # 1. Limpiar y obtener JSON v√°lido
            try:
                json_str = self._clean_json_response(response)
                logger.debug("1Ô∏è‚É£ JSON limpio:")
                logger.debug(json_str)
            except ValueError as e:
                logger.error(f"‚ùå Error limpiando JSON: {str(e)}")
                return False
            
            # 2. Intentar parsear JSON
            try:
                data = json.loads(json_str)
                logger.debug("2Ô∏è‚É£ JSON parseado correctamente")
            except json.JSONDecodeError as e:
                logger.error(f"‚ùå Error parseando JSON: {str(e)}")
                logger.error("Respuesta problem√°tica:")
                logger.error(json_str)
                return False
            
            # 3. Validar campos requeridos
            required_fields = [
                'term_in_english',
                'related_terms',
                'test_types',
                'loinc_codes',
                'keywords'
            ]
            
            missing_fields = []
            for field in required_fields:
                if field not in data:
                    missing_fields.append(field)
            
            if missing_fields:
                logger.error(f"‚ùå Faltan campos requeridos: {missing_fields}")
                return False
                    
            logger.info("‚úÖ Todos los campos requeridos est√°n presentes")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error validando respuesta: {str(e)}")
            return False

    def process_term(
        self, 
        term: str,
        install_id: str,
        model: str = "gpt-4o",
        temperature: float = 0.75
    ) -> Optional[Dict[str, Any]]:
        """
        Procesa un t√©rmino m√©dico usando OpenAI para obtener informaci√≥n estructurada
        Args:
            term: T√©rmino m√©dico a analizar
            install_id: ID de instalaci√≥n del usuario
            model: Modelo de OpenAI a usar (default: gpt-4o)
            temperature: Temperatura para la respuesta (default: 0.75)
        Returns:
            Dict con la informaci√≥n estructurada o None si hay error
        """
        try:
            # Validar inicializaci√≥n
            if not self.initialized:
                logger.error("‚ùå Servicio no inicializado")
                return None

            logger.info("=" * 50)
            logger.info("üîç INICIO PROCESO DE T√âRMINO")
            logger.info(f"üìù T√©rmino recibido: '{term}'")
            logger.info(f"üîë Install ID: {install_id}")
            logger.info(f"‚öôÔ∏è Configuraci√≥n: model={model}, temperature={temperature}")

            # Validar t√©rmino
            if not term or not isinstance(term, str):
                logger.error("‚ùå T√©rmino inv√°lido")
                logger.error(f"Tipo recibido: {type(term)}")
                logger.error(f"Valor recibido: {term}")
                return None

            # Construir el prompt
            user_prompt = f"""Analyze the following laboratory test or medical term and provide relevant information for LOINC search:
            Term: {term}"""
            logger.info("üìã User Prompt construido:")
            logger.info("-" * 40)
            logger.info(user_prompt)
            logger.info("-" * 40)

            # Procesar con OpenAI usando lazy loading
            logger.info("üîÑ Obteniendo OpenAIService...")
            if not self.openai_service:
                logger.error("‚ùå No se pudo obtener OpenAIService")
                return None
            
            logger.info("‚úÖ OpenAIService obtenido correctamente")

            # Procesar con OpenAI
            logger.info("üöÄ Enviando solicitud a OpenAI...")
            response = self.openai_service.process_query(
                user_prompt=user_prompt,
                install_id=install_id,
                model=model,
                temperature=temperature,
                system_prompt=DEFAULT_SYSTEM_PROMPT
            )

            if not response:
                logger.error("‚ùå No se obtuvo respuesta de OpenAI")
                return None

            logger.info("üì© Respuesta recibida de OpenAI")
            
            # Validar formato de respuesta
            logger.info("üîç Validando formato de respuesta...")
            try:
                # Limpiar y obtener JSON v√°lido
                json_str = self._clean_json_response(response)
                # Parsear a diccionario
                data = json.loads(json_str)
                
                # A√±adir el t√©rmino original
                enriched_data = {
                    "original_term": term,
                    **data
                }
                
                logger.debug("‚úÖ T√©rmino procesado correctamente")
                return enriched_data
                
            except Exception as e:
                logger.error(f"‚ùå Error procesando t√©rmino: {str(e)}")
                return None

        except Exception as e:
            logger.error("=" * 50)
            logger.error("‚ùå ERROR EN PROCESO DE T√âRMINO")
            logger.error(f"Tipo de error: {type(e).__name__}")
            logger.error(f"Mensaje: {str(e)}")
            logger.exception("Detalles del error:")
            logger.error("=" * 50)
            return None

    def register_handlers(self, socketio):
        """Registra los handlers de eventos para Ontolog√≠a"""
        if not socketio:
            return
            
        logger.debug("üîç Registrando handlers Ontolog√≠a")
        
        @socketio.on('ontology.search')
        def handle_search(data):
            try:
                # Validar datos
                if not isinstance(data, dict):
                    logger.error("‚ùå Datos inv√°lidos para b√∫squeda")
                    emit('ontology.search_result', {
                        'status': 'error',
                        'message': 'Datos inv√°lidos'
                    })
                    return

                # Procesar b√∫squeda
                result = self.process_search(data)
                if not result:
                    logger.error("‚ùå Error procesando b√∫squeda")
                    emit('ontology.search_result', {
                        'status': 'error',
                        'message': 'Error procesando b√∫squeda'
                    })
                    return

                # Emitir resultado
                emit('ontology.search_result', {
                    'status': 'success',
                    'data': result
                })

            except Exception as e:
                logger.error(f"‚ùå Error en b√∫squeda: {str(e)}")
                emit('ontology.search_result', {
                    'status': 'error',
                    'message': str(e)
                })

# Crear instancia global
ontology_service = OntologyService() 